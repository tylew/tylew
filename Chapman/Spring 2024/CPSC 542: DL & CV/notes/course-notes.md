
TWIMLAI podcast
'this week in ml & ai'

For quiz 2:
Explain-ability of transfer learning 


- Temporal
- Spacial

Limitations:
- models aren't always 'plug-n-play'
- models will form a bias around their training data

## Auto Encoder
Output should be as close as possible to input


Check using 'reconstruction-error' -- some loss function

U-Nets used for segmentation in 2D

### Vision
- Sensors (eyes) gather information about surroundings
  - depth
  - color
- Forming ideas of surroundings
  - Classification

NN's:
- Layers
  - Nodes
  - Activation functions
- Flexibility
  - non-linear relationships
- Loss function
  - representation of error, want to minimize
- Other sets of parameters

For next week review:
- Gradient descent
- Back prop
- Convocational NN intro slides

---

Convolution layer 
Cross-Correlation
Feature detection in space

Backpropogation:
1. Initialization of network
2. Forward pass
3. Calculate error/loss
4. Backward pass (backpropogation of error)
5. Repeat 2-4 until converge/epochs

# Feb 15

